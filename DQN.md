---
title: "Deep Reinforcement Learning paper notes"
permalink: /
layout: default
---

## 论文内容记录
The environment(or emulator) is The Arcade Learning Environment.

进行实际仿真的时候应当采用模拟、训练相互独立的形式进行，这样的目的是提高训练的效率，减少渲染环境所消耗的电脑算力。游戏的分数是根据规定的*奖励函数*来进行计算的.
在进行实际的演算的过程中，通过设定最大的时间步长，即设定最多的运行步数(step次数)，超过后将会进入下一次迭代，并在迭代开始时进行reset().

论文中采用的是像素级别的强化学习进行的训练，通过记录整个屏幕的图像来进行训练，通过观察其中的动作数值以及状态数值的序列来进行的相关的游戏策略的设计。所有的游戏策略是一个有限的时间步长就可以实现的过程，通过MDP将每个序列作为一个确定的状态来进行马尔可夫决策过程规划的解决方法，来进行奖励的计算。每个智能体的目标均为利用模拟器来获取未来能够获取最大奖励函数的动作。

## Formula Record
$R_t=\sum_{t'=t}^T\gamma^{t'-t}r_{t'}$